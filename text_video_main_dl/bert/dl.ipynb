{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../video_features/resnet_features.pkl', 'rb') as f:\n",
    "    video_features_dict = pickle.load(f)\n",
    "\n",
    "for k in video_features_dict:\n",
    "    video_features_dict[k] = np.array(video_features_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.,  72., 120., 168., 480.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [video_features_dict[k].shape[0] for k in video_features_dict]\n",
    "np.percentile(a, [0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFrames = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def getUpdatedFeatures(a, nf):\n",
    "    b = a.copy()\n",
    "    while b.shape[0]<nf:\n",
    "        i = random.randint(0,b.shape[0]-1)\n",
    "        b = np.concatenate((b[:i],np.array([b[i]]),b[i:]))\n",
    "        \n",
    "    while b.shape[0]>nf:\n",
    "        i = random.randint(0,b.shape[0]-1)\n",
    "        b = np.concatenate((b[:i],b[i+1:]))\n",
    "    \n",
    "    return b\n",
    "\n",
    "getUpdatedFeatures(video_features_dict[k], numFrames).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features_dict2 = {}\n",
    "for k in video_features_dict:\n",
    "    video_features_dict2[k] = getUpdatedFeatures(video_features_dict[k], numFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('../../video_features/resnet_features_same_num_frames.pkl', 'wb')\n",
    "pickle.dump(video_features_dict2, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 100, 2048)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../datasets/mustard_dataset/sarcasm_with_id.csv')\n",
    "video_features = []\n",
    "\n",
    "ids = list(data['id'])\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        video_features.append(video_features_dict2[i[:-2]])\n",
    "\n",
    "video_features = np.array(video_features)\n",
    "video_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../datasets/mustard_dataset/sarcasm_data.csv').dropna(axis=0,how='any')\n",
    "\n",
    "features = data['text'].to_list()\n",
    "labels = data['sarcasm'].to_list()\n",
    "\n",
    "text_features = np.load('../../bert embeddings/sarcasm_data_embeddings.npy')\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 2048])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "class TextBasedAttention(Layer):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        V: (nf, vd)\n",
    "        T: (td)\n",
    "    Outputs:\n",
    "        Vp: (nf)\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TextBasedAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                   shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "                                   initializer='random_normal',\n",
    "                                   trainable=True)\n",
    "        self.dense = Dense(input_shape[0][-2], activation='softmax')\n",
    "        super(TextBasedAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        V = x[0]\n",
    "        T = K.expand_dims(x[1], -1)\n",
    "        \n",
    "        p1 = K.permute_dimensions(K.dot(self.w,T), (1, 0, 2))\n",
    "        prod = K.squeeze(K.batch_dot(V, p1), axis=-1)\n",
    "        \n",
    "        scores = self.dense(prod)\n",
    "        scores = K.permute_dimensions(K.repeat(scores, V.shape[-1]), (0, 2, 1))\n",
    "        \n",
    "        vp = K.sum(V*scores, axis=-2)\n",
    "        \n",
    "        return vp\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][-2])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(TextBasedAttention, self).get_config()\n",
    "    \n",
    "T = np.ones((32,768))\n",
    "V = np.ones((32,100,2048))\n",
    "TextBasedAttention()([V,T]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dropout, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 100, 2048)]  0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 768)]        0           []                               \n",
      "                                                                                                  \n",
      " text_based_attention_47 (TextB  (None, 2048)        1582964     ['input_25[0][0]',               \n",
      " asedAttention)                                                   'input_26[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 2816)         0           ['text_based_attention_47[0][0]',\n",
      "                                                                  'input_26[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 2816)         0           ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 1)            2817        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,585,781\n",
      "Trainable params: 1,585,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def myModel():\n",
    "    V = Input(shape=(100, 2048))\n",
    "    T = Input(shape=(768,))\n",
    "    \n",
    "    Vp = TextBasedAttention()([V,T])\n",
    "\n",
    "    f = Concatenate()([Vp, T])\n",
    "    dropout = Dropout(0.5)(f)\n",
    "    output = Dense(1, activation=\"sigmoid\", use_bias=True)(dropout)\n",
    "    \n",
    "    model = Model(inputs=[V,T], outputs=output)\n",
    "    model.compile(b\n",
    "        optimizer=\"adam\", \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall()\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "RANDOM_STATE = 50\n",
    "\n",
    "def create_train_valid(features,labels,train_fraction = 0.7,max_valid=1000):\n",
    "\n",
    "    features,labels = shuffle(features,labels,random_state = RANDOM_STATE)\n",
    "\n",
    "    train_end = max(int(train_fraction*len(labels)),len(labels)-max_valid)\n",
    "\n",
    "    train_features = np.asarray(features[:train_end])\n",
    "    valid_features = np.asarray(features[train_end:])\n",
    "\n",
    "    train_labels = np.asarray(labels[:train_end])\n",
    "    valid_labels = np.asarray(labels[train_end:])\n",
    "    \n",
    "    return train_features,valid_features,train_labels,valid_labels\n",
    "\n",
    "\n",
    "x_train_video, x_valid_video, y_train_video, y_valid_video = create_train_valid(video_features, labels)\n",
    "x_train_text, x_valid_text, y_train_text, y_valid_text = create_train_valid(text_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 sentences\n",
    "# 10 words\n",
    "# 768\n",
    "\n",
    "# 32,10,768 => mean => 32,768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 2s - loss: 0.7413 - binary_accuracy: 0.5381 - precision_28: 0.5333 - recall_28: 0.5581 - val_loss: 0.7780 - val_binary_accuracy: 0.3673 - val_precision_28: 0.3333 - val_recall_28: 0.4091 - 2s/epoch - 311ms/step\n",
      "7/7 - 1s - loss: 0.6473 - binary_accuracy: 0.6328 - precision_28: 0.6647 - recall_28: 0.5256 - val_loss: 0.7686 - val_binary_accuracy: 0.4694 - val_precision_28: 0.4091 - val_recall_28: 0.4091 - 1s/epoch - 194ms/step\n",
      "7/7 - 1s - loss: 0.6705 - binary_accuracy: 0.6166 - precision_28: 0.6231 - recall_28: 0.5767 - val_loss: 0.7711 - val_binary_accuracy: 0.4082 - val_precision_28: 0.3793 - val_recall_28: 0.5000 - 1s/epoch - 179ms/step\n",
      "7/7 - 1s - loss: 0.5834 - binary_accuracy: 0.6767 - precision_28: 0.6556 - recall_28: 0.7349 - val_loss: 0.7531 - val_binary_accuracy: 0.4898 - val_precision_28: 0.4400 - val_recall_28: 0.5000 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.6260 - binary_accuracy: 0.6513 - precision_28: 0.6569 - recall_28: 0.6233 - val_loss: 0.7390 - val_binary_accuracy: 0.5306 - val_precision_28: 0.4762 - val_recall_28: 0.4545 - 1s/epoch - 173ms/step\n",
      "7/7 - 1s - loss: 0.5810 - binary_accuracy: 0.6767 - precision_28: 0.6712 - recall_28: 0.6837 - val_loss: 0.7515 - val_binary_accuracy: 0.4898 - val_precision_28: 0.4444 - val_recall_28: 0.5455 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.5510 - binary_accuracy: 0.7367 - precision_28: 0.7306 - recall_28: 0.7442 - val_loss: 0.7437 - val_binary_accuracy: 0.5306 - val_precision_28: 0.4800 - val_recall_28: 0.5455 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.5691 - binary_accuracy: 0.6928 - precision_28: 0.7253 - recall_28: 0.6140 - val_loss: 0.7360 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.5000 - 1s/epoch - 173ms/step\n",
      "7/7 - 1s - loss: 0.5349 - binary_accuracy: 0.7413 - precision_28: 0.7309 - recall_28: 0.7581 - val_loss: 0.7550 - val_binary_accuracy: 0.4898 - val_precision_28: 0.4444 - val_recall_28: 0.5455 - 1s/epoch - 169ms/step\n",
      "7/7 - 1s - loss: 0.5469 - binary_accuracy: 0.7344 - precision_28: 0.7155 - recall_28: 0.7721 - val_loss: 0.7354 - val_binary_accuracy: 0.5306 - val_precision_28: 0.4800 - val_recall_28: 0.5455 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.5322 - binary_accuracy: 0.7436 - precision_28: 0.7524 - recall_28: 0.7209 - val_loss: 0.7314 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.5455 - 1s/epoch - 173ms/step\n",
      "7/7 - 1s - loss: 0.5163 - binary_accuracy: 0.7460 - precision_28: 0.7293 - recall_28: 0.7767 - val_loss: 0.7293 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.5455 - 1s/epoch - 170ms/step\n",
      "7/7 - 1s - loss: 0.5193 - binary_accuracy: 0.7483 - precision_28: 0.7548 - recall_28: 0.7302 - val_loss: 0.7181 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.4939 - binary_accuracy: 0.7714 - precision_28: 0.7816 - recall_28: 0.7488 - val_loss: 0.7387 - val_binary_accuracy: 0.5306 - val_precision_28: 0.4828 - val_recall_28: 0.6364 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.4938 - binary_accuracy: 0.7737 - precision_28: 0.7511 - recall_28: 0.8140 - val_loss: 0.7154 - val_binary_accuracy: 0.5102 - val_precision_28: 0.4545 - val_recall_28: 0.4545 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.4787 - binary_accuracy: 0.7621 - precision_28: 0.7857 - recall_28: 0.7163 - val_loss: 0.7164 - val_binary_accuracy: 0.5306 - val_precision_28: 0.4783 - val_recall_28: 0.5000 - 1s/epoch - 170ms/step\n",
      "7/7 - 1s - loss: 0.4816 - binary_accuracy: 0.7667 - precision_28: 0.7500 - recall_28: 0.7953 - val_loss: 0.7189 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.5455 - 1s/epoch - 176ms/step\n",
      "7/7 - 1s - loss: 0.4499 - binary_accuracy: 0.8129 - precision_28: 0.7913 - recall_28: 0.8465 - val_loss: 0.7123 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.4545 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.4579 - binary_accuracy: 0.7852 - precision_28: 0.8081 - recall_28: 0.7442 - val_loss: 0.7131 - val_binary_accuracy: 0.5714 - val_precision_28: 0.5263 - val_recall_28: 0.4545 - 1s/epoch - 168ms/step\n",
      "7/7 - 1s - loss: 0.4383 - binary_accuracy: 0.7898 - precision_28: 0.7650 - recall_28: 0.8326 - val_loss: 0.7320 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5385 - val_recall_28: 0.6364 - 1s/epoch - 173ms/step\n",
      "7/7 - 1s - loss: 0.4458 - binary_accuracy: 0.8060 - precision_28: 0.7787 - recall_28: 0.8512 - val_loss: 0.7069 - val_binary_accuracy: 0.5714 - val_precision_28: 0.5263 - val_recall_28: 0.4545 - 1s/epoch - 169ms/step\n",
      "7/7 - 1s - loss: 0.4447 - binary_accuracy: 0.7852 - precision_28: 0.7961 - recall_28: 0.7628 - val_loss: 0.7032 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 169ms/step\n",
      "7/7 - 1s - loss: 0.4286 - binary_accuracy: 0.7991 - precision_28: 0.7783 - recall_28: 0.8326 - val_loss: 0.7372 - val_binary_accuracy: 0.5510 - val_precision_28: 0.5000 - val_recall_28: 0.6364 - 1s/epoch - 177ms/step\n",
      "7/7 - 1s - loss: 0.4334 - binary_accuracy: 0.8152 - precision_28: 0.7801 - recall_28: 0.8744 - val_loss: 0.7026 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 171ms/step\n",
      "7/7 - 1s - loss: 0.4182 - binary_accuracy: 0.7991 - precision_28: 0.8516 - recall_28: 0.7209 - val_loss: 0.7131 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5500 - val_recall_28: 0.5000 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.4262 - binary_accuracy: 0.8083 - precision_28: 0.7619 - recall_28: 0.8930 - val_loss: 0.7260 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5385 - val_recall_28: 0.6364 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.4112 - binary_accuracy: 0.8314 - precision_28: 0.8198 - recall_28: 0.8465 - val_loss: 0.7054 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.4170 - binary_accuracy: 0.8199 - precision_28: 0.8408 - recall_28: 0.7860 - val_loss: 0.7066 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5500 - val_recall_28: 0.5000 - 1s/epoch - 176ms/step\n",
      "7/7 - 1s - loss: 0.4002 - binary_accuracy: 0.8129 - precision_28: 0.8045 - recall_28: 0.8233 - val_loss: 0.7088 - val_binary_accuracy: 0.6327 - val_precision_28: 0.5909 - val_recall_28: 0.5909 - 1s/epoch - 179ms/step\n",
      "7/7 - 1s - loss: 0.3984 - binary_accuracy: 0.8499 - precision_28: 0.8289 - recall_28: 0.8791 - val_loss: 0.6991 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 185ms/step\n",
      "7/7 - 1s - loss: 0.3929 - binary_accuracy: 0.8360 - precision_28: 0.8429 - recall_28: 0.8233 - val_loss: 0.7036 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5500 - val_recall_28: 0.5000 - 1s/epoch - 180ms/step\n",
      "7/7 - 1s - loss: 0.3659 - binary_accuracy: 0.8614 - precision_28: 0.8475 - recall_28: 0.8791 - val_loss: 0.7018 - val_binary_accuracy: 0.6122 - val_precision_28: 0.5789 - val_recall_28: 0.5000 - 1s/epoch - 176ms/step\n",
      "7/7 - 1s - loss: 0.3840 - binary_accuracy: 0.8476 - precision_28: 0.8531 - recall_28: 0.8372 - val_loss: 0.7060 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5500 - val_recall_28: 0.5000 - 1s/epoch - 186ms/step\n",
      "7/7 - 1s - loss: 0.3879 - binary_accuracy: 0.8383 - precision_28: 0.8139 - recall_28: 0.8744 - val_loss: 0.7041 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 171ms/step\n",
      "7/7 - 1s - loss: 0.3712 - binary_accuracy: 0.8591 - precision_28: 0.8850 - recall_28: 0.8233 - val_loss: 0.7128 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5500 - val_recall_28: 0.5000 - 1s/epoch - 168ms/step\n",
      "7/7 - 1s - loss: 0.3729 - binary_accuracy: 0.8383 - precision_28: 0.7866 - recall_28: 0.9256 - val_loss: 0.7220 - val_binary_accuracy: 0.6122 - val_precision_28: 0.5652 - val_recall_28: 0.5909 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.3657 - binary_accuracy: 0.8568 - precision_28: 0.8592 - recall_28: 0.8512 - val_loss: 0.7119 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 173ms/step\n",
      "7/7 - 1s - loss: 0.3724 - binary_accuracy: 0.8568 - precision_28: 0.8806 - recall_28: 0.8233 - val_loss: 0.7190 - val_binary_accuracy: 0.6122 - val_precision_28: 0.5789 - val_recall_28: 0.5000 - 1s/epoch - 169ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 1s - loss: 0.3578 - binary_accuracy: 0.8637 - precision_28: 0.8514 - recall_28: 0.8791 - val_loss: 0.7258 - val_binary_accuracy: 0.6122 - val_precision_28: 0.5652 - val_recall_28: 0.5909 - 1s/epoch - 184ms/step\n",
      "7/7 - 1s - loss: 0.3319 - binary_accuracy: 0.8868 - precision_28: 0.8640 - recall_28: 0.9163 - val_loss: 0.7172 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 176ms/step\n",
      "7/7 - 1s - loss: 0.3659 - binary_accuracy: 0.8453 - precision_28: 0.8491 - recall_28: 0.8372 - val_loss: 0.7178 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 182ms/step\n",
      "7/7 - 1s - loss: 0.3527 - binary_accuracy: 0.8637 - precision_28: 0.8421 - recall_28: 0.8930 - val_loss: 0.7137 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.3439 - binary_accuracy: 0.8707 - precision_28: 0.8383 - recall_28: 0.9163 - val_loss: 0.7190 - val_binary_accuracy: 0.6531 - val_precision_28: 0.6190 - val_recall_28: 0.5909 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.3468 - binary_accuracy: 0.8453 - precision_28: 0.8592 - recall_28: 0.8233 - val_loss: 0.7173 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 169ms/step\n",
      "7/7 - 1s - loss: 0.3513 - binary_accuracy: 0.8707 - precision_28: 0.8565 - recall_28: 0.8884 - val_loss: 0.7382 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5417 - val_recall_28: 0.5909 - 1s/epoch - 172ms/step\n",
      "7/7 - 1s - loss: 0.3403 - binary_accuracy: 0.8868 - precision_28: 0.8487 - recall_28: 0.9395 - val_loss: 0.7235 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 171ms/step\n",
      "7/7 - 1s - loss: 0.3407 - binary_accuracy: 0.8707 - precision_28: 0.8878 - recall_28: 0.8465 - val_loss: 0.7238 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 171ms/step\n",
      "7/7 - 1s - loss: 0.3332 - binary_accuracy: 0.8799 - precision_28: 0.8655 - recall_28: 0.8977 - val_loss: 0.7555 - val_binary_accuracy: 0.5714 - val_precision_28: 0.5185 - val_recall_28: 0.6364 - 1s/epoch - 171ms/step\n",
      "7/7 - 1s - loss: 0.3427 - binary_accuracy: 0.8614 - precision_28: 0.8414 - recall_28: 0.8884 - val_loss: 0.7243 - val_binary_accuracy: 0.5918 - val_precision_28: 0.5556 - val_recall_28: 0.4545 - 1s/epoch - 174ms/step\n",
      "7/7 - 1s - loss: 0.3119 - binary_accuracy: 0.9007 - precision_28: 0.9216 - recall_28: 0.8744 - val_loss: 0.7302 - val_binary_accuracy: 0.6327 - val_precision_28: 0.6000 - val_recall_28: 0.5455 - 1s/epoch - 168ms/step\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "s = 0\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    history = model.fit(x=[x_train_video, x_train_text], \n",
    "              y=y_train_video, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=1, \n",
    "              verbose=2,\n",
    "              validation_split=0.1)\n",
    "    \n",
    "    S = history.history[\"val_binary_accuracy\"][0]\n",
    "    if S > s:\n",
    "        s = S\n",
    "        model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 67ms/step - loss: 0.5932 - binary_accuracy: 0.7067 - precision_29: 0.7238 - recall_29: 0.7037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5931963324546814, 0.7067307829856873, 0.723809540271759, 0.7037037014961243]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel = myModel()\n",
    "newModel.load_weights(\"model_weights.h5\")\n",
    "\n",
    "newModel.evaluate(\n",
    "    x=[x_valid_video, x_valid_text], \n",
    "    y=y_valid_video,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "svm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "54382ae67bf97b4da5fbc6bddc0d7ed644b3797b6f0fd66a4d7a68da377cfe58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
