{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../video_features/resnet_features_same_num_frames.pkl', 'rb') as f:\n",
    "    video_features_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 100, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../datasets/mustard_dataset/sarcasm_with_id.csv')\n",
    "video_features = []\n",
    "\n",
    "ids = list(data['id'])\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        video_features.append(video_features_dict[i[:-2]])\n",
    "\n",
    "video_features = np.array(video_features)\n",
    "video_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"../../bert embeddings/bert_features.h5\")\n",
    "text_features_dict = {}\n",
    "for k in list(f.keys()):\n",
    "    text_features_dict[k] = np.array(f[k])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 20, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = []\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        text_features.append(text_features_dict[i])\n",
    "\n",
    "text_features = np.array(text_features)\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_60_1</td>\n",
       "      <td>It's just a privilege to watch your mind at work.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_60_2</td>\n",
       "      <td>It's just a privilege to look at your mind at ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1_70_1</td>\n",
       "      <td>I don't think I'll be able to stop thinking ab...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1_70_2</td>\n",
       "      <td>I don't think I can stop thinking about it.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1_80_1</td>\n",
       "      <td>Since it's not bee season, you can have my epi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                                          utterance  \\\n",
       "0           0  1_60_1  It's just a privilege to watch your mind at work.   \n",
       "1           1  1_60_2  It's just a privilege to look at your mind at ...   \n",
       "2           2  1_70_1  I don't think I'll be able to stop thinking ab...   \n",
       "3           3  1_70_2        I don't think I can stop thinking about it.   \n",
       "4           4  1_80_1  Since it's not bee season, you can have my epi...   \n",
       "\n",
       "   sarcasm  \n",
       "0     True  \n",
       "1     True  \n",
       "2     True  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDict = {}\n",
    "\n",
    "sarcasm = list(data['sarcasm'])\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    labelDict[ids[i]] = sarcasm[i]\n",
    "    \n",
    "labels = []\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        labels.append(int(labelDict[i]))\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "class coAttention_para(Layer):\n",
    "    \"\"\"\n",
    "    self-defined parallel co-attention layer.\n",
    "    inputs: [tFeature, iFeature]\n",
    "    outputs: [coFeature]\n",
    "    dimension:\n",
    "    input dimensions: [(batch_size, seq_length, embedding_size), (batch_size, num_img_region, 2*hidden_size)]\n",
    "        considering subsequent operation, better to set embedding_size == 2*hidden_size\n",
    "    output dimensions:[(batch_size, 2*hidden_size)]\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_k, **kwargs):\n",
    "        super(coAttention_para, self).__init__(**kwargs)\n",
    "        self.dim_k = dim_k  # internal tensor dimension\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('A Co-Attention_para layer should be called '\n",
    "                             'on a list of inputs.')\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n",
    "                             'Got '+str(len(input_shape))+'inputs.')\n",
    "        self.embedding_size = input_shape[0][-1]\n",
    "        self.num_region = input_shape[1][1]\n",
    "        self.seq_len = input_shape[0][1]\n",
    "        \"\"\"\n",
    "        naming variables following the VQA paper\n",
    "        \"\"\"\n",
    "        self.Wb = self.add_weight(name=\"Wb\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.embedding_size),\n",
    "                                  trainable=True)\n",
    "        self.Wq = self.add_weight(name=\"Wq\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.dim_k),\n",
    "                                  trainable=True)\n",
    "        self.Wv = self.add_weight(name=\"Wv\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.dim_k),\n",
    "                                  trainable=True)\n",
    "        self.Whv = self.add_weight(name=\"Whv\",\n",
    "                                   initializer=\"random_normal\",\n",
    "                                   # initializer=\"ones\",\n",
    "                                   shape=(self.dim_k, 1),\n",
    "                                   trainable=True)\n",
    "        self.Whq = self.add_weight(name=\"Whq\",\n",
    "                                   initializer=\"random_normal\",\n",
    "                                   # initializer=\"ones\",\n",
    "                                   shape=(self.dim_k, 1),\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(coAttention_para, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        tFeature = inputs[0]\n",
    "        iFeature = inputs[1]\n",
    "        # affinity matrix C\n",
    "        affi_mat = K.dot(tFeature, self.Wb)\n",
    "        affi_mat = K.batch_dot(affi_mat, K.permute_dimensions(iFeature, (0, 2, 1)))  # (batch_size, seq_len, num_region)\n",
    "        # Hq, Hv, av, aq\n",
    "        tmp_Hv = K.dot(tFeature, self.Wq)\n",
    "        Hv = K.dot(iFeature, self.Wv) + K.batch_dot(K.permute_dimensions(affi_mat, (0, 2, 1)), tmp_Hv)\n",
    "        Hv = K.tanh(Hv)\n",
    "        av = K.softmax(K.squeeze(K.dot(Hv, self.Whv), axis=-1))\n",
    "\n",
    "        tmp_Hq = K.dot(iFeature, self.Wv)\n",
    "        Hq = K.dot(tFeature, self.Wq) + K.batch_dot(affi_mat, tmp_Hq)\n",
    "        Hq = K.tanh(Hq)\n",
    "        aq = K.softmax(K.squeeze(K.dot(Hq, self.Whq), axis=-1))\n",
    "\n",
    "        av = K.permute_dimensions(K.repeat(av, self.embedding_size), (0, 2, 1))\n",
    "        aq = K.permute_dimensions(K.repeat(aq, self.embedding_size), (0, 2, 1))\n",
    "\n",
    "        tfeature = K.sum(aq * tFeature, axis=1)\n",
    "        ifeature = K.sum(av * iFeature, axis=1)\n",
    "\n",
    "        return tfeature+ifeature\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(coAttention_para, self).get_config()\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = (input_shape[0][0], input_shape[0][-1])\n",
    "        return output_shape\n",
    "    \n",
    "T = np.ones((32,20,768))\n",
    "V = np.ones((32,100,768))\n",
    "coAttention_para(300)([T,V]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dropout, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 2048)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100, 768)     1573632     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " co_attention_para_1 (coAttenti  (None, 768)         1051224     ['input_2[0][0]',                \n",
      " on_para)                                                         'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['co_attention_para_1[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,625,625\n",
      "Trainable params: 2,625,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def myModel():\n",
    "    V = Input(shape=(100, 2048))\n",
    "    T = Input(shape=(20,768))\n",
    "    \n",
    "    Vp = Dense(768)(V)\n",
    "    \n",
    "\n",
    "    f = coAttention_para(300)([T, Vp])\n",
    "    dropout = Dropout(0.5)(f)\n",
    "    output = Dense(1, activation=\"sigmoid\", use_bias=True)(dropout)\n",
    "    \n",
    "    model = Model(inputs=[V,T], outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall()\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "RANDOM_STATE = 50\n",
    "\n",
    "def create_train_valid(features,labels,train_fraction = 0.7,max_valid=1000):\n",
    "\n",
    "    features,labels = shuffle(features,labels,random_state = RANDOM_STATE)\n",
    "\n",
    "    train_end = max(int(train_fraction*len(labels)),len(labels)-max_valid)\n",
    "\n",
    "    train_features = np.asarray(features[:train_end])\n",
    "    valid_features = np.asarray(features[train_end:])\n",
    "\n",
    "    train_labels = np.asarray(labels[:train_end])\n",
    "    valid_labels = np.asarray(labels[train_end:])\n",
    "    \n",
    "    return train_features,valid_features,train_labels,valid_labels\n",
    "\n",
    "\n",
    "x_train_video, x_valid_video, y_train_video, y_valid_video = create_train_valid(video_features, labels)\n",
    "x_train_text, x_valid_text, y_train_text, y_valid_text = create_train_valid(text_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 5s - loss: 0.8011 - binary_accuracy: 0.5335 - precision_2: 0.5294 - recall_2: 0.5442 - val_loss: 0.7035 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6667 - val_recall_2: 0.4545 - 5s/epoch - 697ms/step\n",
      "7/7 - 3s - loss: 0.6218 - binary_accuracy: 0.6767 - precision_2: 0.6984 - recall_2: 0.6140 - val_loss: 0.7192 - val_binary_accuracy: 0.5306 - val_precision_2: 0.4815 - val_recall_2: 0.5909 - 3s/epoch - 485ms/step\n",
      "7/7 - 4s - loss: 0.6489 - binary_accuracy: 0.7090 - precision_2: 0.7014 - recall_2: 0.7209 - val_loss: 0.6978 - val_binary_accuracy: 0.6327 - val_precision_2: 0.6111 - val_recall_2: 0.5000 - 4s/epoch - 597ms/step\n",
      "7/7 - 4s - loss: 0.6138 - binary_accuracy: 0.7344 - precision_2: 0.7427 - recall_2: 0.7116 - val_loss: 0.7110 - val_binary_accuracy: 0.6327 - val_precision_2: 0.5833 - val_recall_2: 0.6364 - 4s/epoch - 590ms/step\n",
      "7/7 - 4s - loss: 0.5670 - binary_accuracy: 0.7390 - precision_2: 0.7277 - recall_2: 0.7581 - val_loss: 0.7756 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6667 - val_recall_2: 0.4545 - 4s/epoch - 552ms/step\n",
      "7/7 - 4s - loss: 0.5221 - binary_accuracy: 0.7945 - precision_2: 0.7864 - recall_2: 0.8047 - val_loss: 0.9344 - val_binary_accuracy: 0.6327 - val_precision_2: 0.6429 - val_recall_2: 0.4091 - 4s/epoch - 549ms/step\n",
      "7/7 - 4s - loss: 0.6313 - binary_accuracy: 0.7483 - precision_2: 0.7304 - recall_2: 0.7814 - val_loss: 0.9538 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6923 - val_recall_2: 0.4091 - 4s/epoch - 622ms/step\n",
      "7/7 - 5s - loss: 0.5857 - binary_accuracy: 0.7783 - precision_2: 0.7874 - recall_2: 0.7581 - val_loss: 0.8376 - val_binary_accuracy: 0.6122 - val_precision_2: 0.5789 - val_recall_2: 0.5000 - 5s/epoch - 674ms/step\n",
      "7/7 - 4s - loss: 0.5221 - binary_accuracy: 0.7852 - precision_2: 0.7877 - recall_2: 0.7767 - val_loss: 0.8644 - val_binary_accuracy: 0.6122 - val_precision_2: 0.5714 - val_recall_2: 0.5455 - 4s/epoch - 626ms/step\n",
      "7/7 - 5s - loss: 0.4352 - binary_accuracy: 0.8129 - precision_2: 0.8284 - recall_2: 0.7860 - val_loss: 0.8661 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6471 - val_recall_2: 0.5000 - 5s/epoch - 670ms/step\n",
      "7/7 - 4s - loss: 0.4580 - binary_accuracy: 0.7945 - precision_2: 0.7788 - recall_2: 0.8186 - val_loss: 0.8985 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6923 - val_recall_2: 0.4091 - 4s/epoch - 608ms/step\n",
      "7/7 - 4s - loss: 0.4847 - binary_accuracy: 0.7968 - precision_2: 0.7981 - recall_2: 0.7907 - val_loss: 0.8534 - val_binary_accuracy: 0.6735 - val_precision_2: 0.7143 - val_recall_2: 0.4545 - 4s/epoch - 594ms/step\n",
      "7/7 - 4s - loss: 0.3715 - binary_accuracy: 0.8430 - precision_2: 0.8356 - recall_2: 0.8512 - val_loss: 0.8713 - val_binary_accuracy: 0.6122 - val_precision_2: 0.5882 - val_recall_2: 0.4545 - 4s/epoch - 600ms/step\n",
      "7/7 - 4s - loss: 0.3935 - binary_accuracy: 0.8406 - precision_2: 0.8230 - recall_2: 0.8651 - val_loss: 0.9672 - val_binary_accuracy: 0.6735 - val_precision_2: 0.7143 - val_recall_2: 0.4545 - 4s/epoch - 596ms/step\n",
      "7/7 - 5s - loss: 0.3900 - binary_accuracy: 0.8476 - precision_2: 0.8311 - recall_2: 0.8698 - val_loss: 1.0625 - val_binary_accuracy: 0.6735 - val_precision_2: 0.7143 - val_recall_2: 0.4545 - 5s/epoch - 653ms/step\n",
      "7/7 - 5s - loss: 0.3965 - binary_accuracy: 0.8176 - precision_2: 0.8366 - recall_2: 0.7860 - val_loss: 0.9904 - val_binary_accuracy: 0.6122 - val_precision_2: 0.5556 - val_recall_2: 0.6818 - 5s/epoch - 657ms/step\n",
      "7/7 - 4s - loss: 0.4024 - binary_accuracy: 0.8430 - precision_2: 0.8551 - recall_2: 0.8233 - val_loss: 0.9723 - val_binary_accuracy: 0.5714 - val_precision_2: 0.5185 - val_recall_2: 0.6364 - 4s/epoch - 552ms/step\n",
      "7/7 - 4s - loss: 0.4918 - binary_accuracy: 0.8014 - precision_2: 0.7945 - recall_2: 0.8093 - val_loss: 0.9701 - val_binary_accuracy: 0.5918 - val_precision_2: 0.5556 - val_recall_2: 0.4545 - 4s/epoch - 546ms/step\n",
      "7/7 - 4s - loss: 0.3709 - binary_accuracy: 0.8568 - precision_2: 0.8370 - recall_2: 0.8837 - val_loss: 1.0399 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6667 - val_recall_2: 0.4545 - 4s/epoch - 587ms/step\n",
      "7/7 - 4s - loss: 0.3223 - binary_accuracy: 0.8684 - precision_2: 0.8435 - recall_2: 0.9023 - val_loss: 1.0407 - val_binary_accuracy: 0.6531 - val_precision_2: 0.6667 - val_recall_2: 0.4545 - 4s/epoch - 558ms/step\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "s = 0\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    history = model.fit(x=[x_train_video, x_train_text], \n",
    "              y=y_train_video, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=1, \n",
    "              verbose=2,\n",
    "              validation_split=0.1)\n",
    "    \n",
    "    S = history.history[\"val_binary_accuracy\"][0]\n",
    "    if S > s:\n",
    "        s = S\n",
    "        model.save_weights(\"model_v2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 15s - loss: 1.0543 - binary_accuracy: 0.5207 - precision_9: 0.5143 - recall_9: 0.4557 - 15s/epoch - 2s/step\n",
      "4/4 [==============================] - 4s 455ms/step - loss: 0.7052 - binary_accuracy: 0.6202 - precision_9: 0.5858 - recall_9: 0.9167\n",
      "8/8 - 11s - loss: 0.8077 - binary_accuracy: 0.6224 - precision_9: 0.6291 - recall_9: 0.5654 - 11s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.6796 - binary_accuracy: 0.6490 - precision_9: 0.6074 - recall_9: 0.9167\n",
      "8/8 - 9s - loss: 0.7712 - binary_accuracy: 0.6556 - precision_9: 0.6485 - recall_9: 0.6540 - 9s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.6362 - binary_accuracy: 0.6635 - precision_9: 0.7159 - recall_9: 0.5833\n",
      "8/8 - 14s - loss: 0.6766 - binary_accuracy: 0.7116 - precision_9: 0.6929 - recall_9: 0.7426 - 14s/epoch - 2s/step\n",
      "4/4 [==============================] - 4s 736ms/step - loss: 0.6924 - binary_accuracy: 0.6538 - precision_9: 0.7500 - recall_9: 0.5000\n",
      "8/8 - 17s - loss: 0.6941 - binary_accuracy: 0.7012 - precision_9: 0.6914 - recall_9: 0.7089 - 17s/epoch - 2s/step\n",
      "4/4 [==============================] - 3s 593ms/step - loss: 0.7500 - binary_accuracy: 0.6394 - precision_9: 0.7797 - recall_9: 0.4259\n",
      "8/8 - 12s - loss: 0.6559 - binary_accuracy: 0.7178 - precision_9: 0.7095 - recall_9: 0.7215 - 12s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7311 - binary_accuracy: 0.6635 - precision_9: 0.7568 - recall_9: 0.5185\n",
      "8/8 - 11s - loss: 0.7215 - binary_accuracy: 0.7033 - precision_9: 0.7217 - recall_9: 0.6456 - 11s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.8293 - binary_accuracy: 0.6202 - precision_9: 0.5901 - recall_9: 0.8796\n",
      "8/8 - 10s - loss: 0.4670 - binary_accuracy: 0.7884 - precision_9: 0.7897 - recall_9: 0.7764 - 10s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 347ms/step - loss: 0.7899 - binary_accuracy: 0.6346 - precision_9: 0.7222 - recall_9: 0.4815\n",
      "8/8 - 8s - loss: 0.5029 - binary_accuracy: 0.7905 - precision_9: 0.7833 - recall_9: 0.7932 - 8s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 358ms/step - loss: 0.6845 - binary_accuracy: 0.6442 - precision_9: 0.6635 - recall_9: 0.6389\n",
      "8/8 - 9s - loss: 0.3906 - binary_accuracy: 0.8402 - precision_9: 0.8279 - recall_9: 0.8523 - 9s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 394ms/step - loss: 0.6917 - binary_accuracy: 0.6490 - precision_9: 0.6606 - recall_9: 0.6667\n",
      "8/8 - 9s - loss: 0.4220 - binary_accuracy: 0.8299 - precision_9: 0.8270 - recall_9: 0.8270 - 9s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.7282 - binary_accuracy: 0.6538 - precision_9: 0.6364 - recall_9: 0.7778\n",
      "8/8 - 9s - loss: 0.3990 - binary_accuracy: 0.8154 - precision_9: 0.8083 - recall_9: 0.8186 - 9s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.7392 - binary_accuracy: 0.6587 - precision_9: 0.6555 - recall_9: 0.7222\n",
      "8/8 - 11s - loss: 0.3837 - binary_accuracy: 0.8195 - precision_9: 0.8024 - recall_9: 0.8397 - 11s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.7619 - binary_accuracy: 0.6250 - precision_9: 0.6293 - recall_9: 0.6759\n",
      "8/8 - 13s - loss: 0.3195 - binary_accuracy: 0.8506 - precision_9: 0.8541 - recall_9: 0.8397 - 13s/epoch - 2s/step\n",
      "4/4 [==============================] - 3s 609ms/step - loss: 0.7727 - binary_accuracy: 0.6346 - precision_9: 0.6600 - recall_9: 0.6111\n",
      "8/8 - 11s - loss: 0.2893 - binary_accuracy: 0.8880 - precision_9: 0.8996 - recall_9: 0.8692 - 11s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 457ms/step - loss: 0.8034 - binary_accuracy: 0.6394 - precision_9: 0.6260 - recall_9: 0.7593\n",
      "8/8 - 11s - loss: 0.2995 - binary_accuracy: 0.8776 - precision_9: 0.8771 - recall_9: 0.8734 - 11s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.7700 - binary_accuracy: 0.6346 - precision_9: 0.6404 - recall_9: 0.6759\n",
      "8/8 - 12s - loss: 0.2678 - binary_accuracy: 0.8693 - precision_9: 0.8686 - recall_9: 0.8650 - 12s/epoch - 2s/step\n",
      "4/4 [==============================] - 2s 510ms/step - loss: 0.7969 - binary_accuracy: 0.6538 - precision_9: 0.6500 - recall_9: 0.7222\n",
      "8/8 - 12s - loss: 0.2506 - binary_accuracy: 0.8859 - precision_9: 0.8611 - recall_9: 0.9156 - 12s/epoch - 2s/step\n",
      "4/4 [==============================] - 2s 490ms/step - loss: 0.9484 - binary_accuracy: 0.6106 - precision_9: 0.6957 - recall_9: 0.4444\n",
      "8/8 - 12s - loss: 0.2309 - binary_accuracy: 0.9004 - precision_9: 0.8826 - recall_9: 0.9198 - 12s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 0.9143 - binary_accuracy: 0.5913 - precision_9: 0.6456 - recall_9: 0.4722\n",
      "8/8 - 10s - loss: 0.2191 - binary_accuracy: 0.9232 - precision_9: 0.9274 - recall_9: 0.9156 - 10s/epoch - 1s/step\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.8814 - binary_accuracy: 0.6250 - precision_9: 0.6471 - recall_9: 0.6111\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    history = model.fit(x=[x_train_video, x_train_text], \n",
    "              y=y_train_video, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=1, \n",
    "              verbose=2)\n",
    "    \n",
    "    a = model.evaluate(\n",
    "            x=[x_valid_video, x_valid_text], \n",
    "            y=y_valid_video,\n",
    "            batch_size=BATCH_SIZE\n",
    "        )\n",
    "    \n",
    "    if a[2] > s1 or (a[2]==s1 and a[3]>s2) or (a[2]==s1 and a[3]==s2 and a[1]>s3):\n",
    "        s3,s1,s2 = a[1:]\n",
    "        model.save_weights(\"model_v2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 385ms/step - loss: 0.7500 - binary_accuracy: 0.6394 - precision_10: 0.7797 - recall_10: 0.4259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7499933838844299,\n",
       " 0.6394230723381042,\n",
       " 0.7796609997749329,\n",
       " 0.42592594027519226]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel = myModel()\n",
    "newModel.load_weights(\"model_v2_weights.h5\")\n",
    "\n",
    "newModel.evaluate(\n",
    "    x=[x_valid_video, x_valid_text], \n",
    "    y=y_valid_video,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.6902378797531128, 0.6634615659713745, 0.737500011920929, 0.5462962985038757]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "svm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "54382ae67bf97b4da5fbc6bddc0d7ed644b3797b6f0fd66a4d7a68da377cfe58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
