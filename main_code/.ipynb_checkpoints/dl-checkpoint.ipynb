{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../video_features/resnet_features_same_num_frames.pkl', 'rb') as f:\n",
    "    video_features_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 100, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/mustard_dataset/sarcasm_with_id.csv')\n",
    "video_features = []\n",
    "\n",
    "ids = list(data['id'])\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        video_features.append(video_features_dict[i[:-2]])\n",
    "\n",
    "video_features = np.array(video_features)\n",
    "video_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"../../bert embeddings/bert_features.h5\")\n",
    "text_features_dict = {}\n",
    "for k in list(f.keys()):\n",
    "    text_features_dict[k] = np.array(f[k])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 20, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = []\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        text_features.append(text_features_dict[i])\n",
    "\n",
    "text_features = np.array(text_features)\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>utterance</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1_60_1</td>\n",
       "      <td>It's just a privilege to watch your mind at work.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_60_2</td>\n",
       "      <td>It's just a privilege to look at your mind at ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1_70_1</td>\n",
       "      <td>I don't think I'll be able to stop thinking ab...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1_70_2</td>\n",
       "      <td>I don't think I can stop thinking about it.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1_80_1</td>\n",
       "      <td>Since it's not bee season, you can have my epi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                                          utterance  \\\n",
       "0           0  1_60_1  It's just a privilege to watch your mind at work.   \n",
       "1           1  1_60_2  It's just a privilege to look at your mind at ...   \n",
       "2           2  1_70_1  I don't think I'll be able to stop thinking ab...   \n",
       "3           3  1_70_2        I don't think I can stop thinking about it.   \n",
       "4           4  1_80_1  Since it's not bee season, you can have my epi...   \n",
       "\n",
       "   sarcasm  \n",
       "0     True  \n",
       "1     True  \n",
       "2     True  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDict = {}\n",
    "\n",
    "sarcasm = list(data['sarcasm'])\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    labelDict[ids[i]] = sarcasm[i]\n",
    "    \n",
    "labels = []\n",
    "\n",
    "for i in ids:\n",
    "    if i[-2:] == \"_1\":\n",
    "        labels.append(int(labelDict[i]))\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "class coAttention_para(Layer):\n",
    "    \"\"\"\n",
    "    self-defined parallel co-attention layer.\n",
    "    inputs: [tFeature, iFeature]\n",
    "    outputs: [coFeature]\n",
    "    dimension:\n",
    "    input dimensions: [(batch_size, seq_length, embedding_size), (batch_size, num_img_region, 2*hidden_size)]\n",
    "        considering subsequent operation, better to set embedding_size == 2*hidden_size\n",
    "    output dimensions:[(batch_size, 2*hidden_size)]\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_k, **kwargs):\n",
    "        super(coAttention_para, self).__init__(**kwargs)\n",
    "        self.dim_k = dim_k  # internal tensor dimension\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('A Co-Attention_para layer should be called '\n",
    "                             'on a list of inputs.')\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A Co-Attention_para layer should be called on a list of 2 inputs.'\n",
    "                             'Got '+str(len(input_shape))+'inputs.')\n",
    "        self.embedding_size = input_shape[0][-1]\n",
    "        self.num_region = input_shape[1][1]\n",
    "        self.seq_len = input_shape[0][1]\n",
    "        \"\"\"\n",
    "        naming variables following the VQA paper\n",
    "        \"\"\"\n",
    "        self.Wb = self.add_weight(name=\"Wb\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.embedding_size),\n",
    "                                  trainable=True)\n",
    "        self.Wq = self.add_weight(name=\"Wq\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.dim_k),\n",
    "                                  trainable=True)\n",
    "        self.Wv = self.add_weight(name=\"Wv\",\n",
    "                                  initializer=\"random_normal\",\n",
    "                                  # initializer=\"ones\",\n",
    "                                  shape=(self.embedding_size, self.dim_k),\n",
    "                                  trainable=True)\n",
    "        self.Whv = self.add_weight(name=\"Whv\",\n",
    "                                   initializer=\"random_normal\",\n",
    "                                   # initializer=\"ones\",\n",
    "                                   shape=(self.dim_k, 1),\n",
    "                                   trainable=True)\n",
    "        self.Whq = self.add_weight(name=\"Whq\",\n",
    "                                   initializer=\"random_normal\",\n",
    "                                   # initializer=\"ones\",\n",
    "                                   shape=(self.dim_k, 1),\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(coAttention_para, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        tFeature = inputs[0]\n",
    "        iFeature = inputs[1]\n",
    "        # affinity matrix C\n",
    "        affi_mat = K.dot(tFeature, self.Wb)\n",
    "        affi_mat = K.batch_dot(affi_mat, K.permute_dimensions(iFeature, (0, 2, 1)))  # (batch_size, seq_len, num_region)\n",
    "        # Hq, Hv, av, aq\n",
    "        tmp_Hv = K.dot(tFeature, self.Wq)\n",
    "        Hv = K.dot(iFeature, self.Wv) + K.batch_dot(K.permute_dimensions(affi_mat, (0, 2, 1)), tmp_Hv)\n",
    "        Hv = K.tanh(Hv)\n",
    "        av = K.softmax(K.squeeze(K.dot(Hv, self.Whv), axis=-1))\n",
    "\n",
    "        tmp_Hq = K.dot(iFeature, self.Wv)\n",
    "        Hq = K.dot(tFeature, self.Wq) + K.batch_dot(affi_mat, tmp_Hq)\n",
    "        Hq = K.tanh(Hq)\n",
    "        aq = K.softmax(K.squeeze(K.dot(Hq, self.Whq), axis=-1))\n",
    "\n",
    "        av = K.permute_dimensions(K.repeat(av, self.embedding_size), (0, 2, 1))\n",
    "        aq = K.permute_dimensions(K.repeat(aq, self.embedding_size), (0, 2, 1))\n",
    "\n",
    "        tfeature = K.sum(aq * tFeature, axis=1)\n",
    "        ifeature = K.sum(av * iFeature, axis=1)\n",
    "\n",
    "        return tfeature+ifeature\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(coAttention_para, self).get_config()\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = (input_shape[0][0], input_shape[0][-1])\n",
    "        return output_shape\n",
    "    \n",
    "T = np.ones((32,20,768))\n",
    "V = np.ones((32,100,768))\n",
    "coAttention_para(300)([T,V]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Dropout, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 20, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 100, 2048)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 20, 768)      4721664     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 100, 768)     8653824     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " co_attention_para_1 (coAttenti  (None, 768)         1051224     ['lstm[0][0]',                   \n",
      " on_para)                                                         'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          98432       ['co_attention_para_1[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            65          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,533,465\n",
      "Trainable params: 14,533,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def myModel(video=True, text=True):        \n",
    "    finalInputs = []\n",
    "\n",
    "    if video and text:\n",
    "        V = Input(shape=(100, 2048))\n",
    "        T = Input(shape=(20,768))\n",
    "        \n",
    "        Tf = LSTM(768, return_sequences=True)(T)\n",
    "        Vf = LSTM(768, return_sequences=True)(V)\n",
    "        \n",
    "        f = coAttention_para(300)([Tf, Vf])\n",
    "\n",
    "        finalInputs.append(V)\n",
    "        finalInputs.append(T)\n",
    "\n",
    "    elif video:\n",
    "        V = Input(shape=(100, 2048))\n",
    "        f = LSTM(768, return_sequences=False)(V)\n",
    "        finalInputs.append(V)\n",
    "        \n",
    "    elif text:\n",
    "        T = Input(shape=(20, 2048))\n",
    "        f = LSTM(768, return_sequences=False)(T)\n",
    "        finalInputs.append(T)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Model can't have 0 inputs\")        \n",
    "\n",
    "    f = Dense(128)(f)\n",
    "    f = Dense(64)(f)\n",
    "    dropout = Dropout(0.5)(f)\n",
    "    output = Dense(1, activation=\"sigmoid\", use_bias=True)(dropout)\n",
    "    \n",
    "    model = Model(inputs=finalInputs, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall()\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# RANDOM_STATE = 50\n",
    "\n",
    "# def create_train_valid(features,labels,train_fraction = 0.7,max_valid=1000):\n",
    "\n",
    "#     features,labels = shuffle(features,labels,random_state = RANDOM_STATE)\n",
    "\n",
    "#     train_end = max(int(train_fraction*len(labels)),len(labels)-max_valid)\n",
    "\n",
    "#     train_features = np.asarray(features[:train_end])\n",
    "#     valid_features = np.asarray(features[train_end:])\n",
    "\n",
    "#     train_labels = np.asarray(labels[:train_end])\n",
    "#     valid_labels = np.asarray(labels[train_end:])\n",
    "    \n",
    "#     return train_features,valid_features,train_labels,valid_labels\n",
    "\n",
    "\n",
    "# x_train_video, x_valid_video, y_train_video, y_valid_video = create_train_valid(video_features, labels)\n",
    "# x_train_text, x_valid_text, y_train_text, y_valid_text = create_train_valid(text_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def getF1Score(pre, rec):\n",
    "    if pre == 0 or rec == 0:\n",
    "        return 0\n",
    "    return (2*pre*rec)/(pre+rec)\n",
    "\n",
    "def kFoldResults(video_feat, text_feat, labels, video=True, text=True, n_splits=5):\n",
    "\n",
    "    kf = KFold(n_splits)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(video_feat):\n",
    "        print(\"Fold \" + str(count + 1) + \":\\n\")\n",
    "        model = myModel(video, text)\n",
    "        s1 = 0\n",
    "\n",
    "        train_x = []\n",
    "        test_x = []\n",
    "        \n",
    "        if video:\n",
    "            train_x.append(np.array([video_feat[index] for index in train_index], dtype='float64'))\n",
    "            test_x.append(np.array([video_feat[index] for index in test_index], dtype='float64'))\n",
    "        if text:\n",
    "            train_x.append(np.array([text_feat[index] for index in train_index], dtype='float64'))\n",
    "            test_x.append(np.array([text_feat[index] for index in test_index], dtype='float64'))\n",
    "\n",
    "        train_y = np.array([labels[index] for index in train_index])\n",
    "        test_y = np.array([labels[index] for index in test_index])\n",
    "\n",
    "        for i in range(1, EPOCHS+1):\n",
    "            history = model.fit(x=train_x, \n",
    "                    y=train_y, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=1, \n",
    "                    verbose=2)\n",
    "            \n",
    "            a = model.evaluate(\n",
    "                    x=test_x, \n",
    "                    y=test_y,\n",
    "                    batch_size=BATCH_SIZE\n",
    "                )\n",
    "\n",
    "            f1 = getF1Score(a[2], a[3])\n",
    "            \n",
    "            if f1 > s1:\n",
    "                s1 = f1\n",
    "                model.save_weights(\"model_v2_weights_\" + str(count) + \".h5\")\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "\n",
      "2\n",
      "(552, 100, 2048)\n",
      "(552, 20, 768)\n",
      "9/9 - 93s - loss: 2.2719 - binary_accuracy: 0.4891 - precision_2: 0.4800 - recall_2: 0.4871 - 93s/epoch - 10s/step\n",
      "3/3 [==============================] - 10s 2s/step - loss: 1.1396 - binary_accuracy: 0.4638 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "kFoldResults(video_features, text_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel()\n",
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    history = model.fit(x=[x_train_video, x_train_text], \n",
    "              y=y_train_video, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=1, \n",
    "              verbose=2)\n",
    "    \n",
    "    a = model.evaluate(\n",
    "            x=[x_valid_video, x_valid_text], \n",
    "            y=y_valid_video,\n",
    "            batch_size=BATCH_SIZE\n",
    "        )\n",
    "    \n",
    "    if a[2] > s1 or (a[2]==s1 and a[3]>s2) or (a[2]==s1 and a[3]==s2 and a[1]>s3):\n",
    "        s3,s1,s2 = a[1:]\n",
    "        model.save_weights(\"model_v2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = myModel()\n",
    "newModel.load_weights(\"model_v2_weights.h5\")\n",
    "\n",
    "newModel.evaluate(\n",
    "    x=[x_valid_video, x_valid_text], \n",
    "    y=y_valid_video,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.6902378797531128, 0.6634615659713745, 0.737500011920929, 0.5462962985038757]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "svm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "54382ae67bf97b4da5fbc6bddc0d7ed644b3797b6f0fd66a4d7a68da377cfe58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
