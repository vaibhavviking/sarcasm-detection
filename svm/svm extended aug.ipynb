{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 01:12:50.511670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-28 01:12:50.511699: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vaibhav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vaibhav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vaibhav/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/vaibhav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "lem = WordNetLemmatizer()\n",
    "RANDOM_STATE = 50\n",
    "UNK_ID = 1\n",
    "PAD_ID = 0\n",
    "MAX_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):    \n",
    "    s =  re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', s)\n",
    "    s = re.sub(r'\\((\\d+)\\)', r'', s)\n",
    "    s = re.sub(r'\\s\\s', ' ', s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9(),!?\\'`]\", \" \", s)\n",
    "    s = re.sub(r\"\\'s\", \" \\'s\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" \\'ve\", s)\n",
    "    s = re.sub(r\"n\\'t\", \" n\\'t\", s)\n",
    "    s = re.sub(r\"\\'re\", \" \\'re\", s)\n",
    "    s = re.sub(r\"\\'d\", \" \\'d\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" \\'ll\", s)\n",
    "    s = re.sub(r\",\", \" , \", s)\n",
    "    s = re.sub(r\"!\", \" ! \", s)\n",
    "    s = re.sub(r\"\\\"\", \" \\\" \", s)\n",
    "    s = re.sub(r\"\\(\", \" ( \", s)\n",
    "    s = re.sub(r\"\\)\", \" ) \", s)\n",
    "    s = re.sub(r\"\\?\", \" ? \", s)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    s = re.sub(r\"\\.\", \" . \", s)\n",
    "    s = re.sub(r\"., \", \" , \", s)\n",
    "    s = re.sub(r\"\\\\n\", \" \", s)\n",
    "    return s.strip().lower()\n",
    "\n",
    "def create_train_valid(features,labels,train_fraction = 0.7,max_valid=500):\n",
    "\n",
    "    features,labels = shuffle(features,labels,random_state = RANDOM_STATE)\n",
    "\n",
    "    train_end = max(int(train_fraction*len(labels)),len(labels)-max_valid)\n",
    "\n",
    "    train_features = np.asarray(features[:train_end])\n",
    "    valid_features = np.asarray(features[train_end:])\n",
    "\n",
    "    train_labels = np.asarray(labels[:train_end])\n",
    "    valid_labels = np.asarray(labels[train_end:])\n",
    "    \n",
    "    return train_features,valid_features,train_labels,valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/extended_mustard_aug.csv')\n",
    "\n",
    "features = data['text'].to_list()\n",
    "labels = data['sarcasm'].to_list()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = create_train_valid(features,labels)\n",
    "training_dict = {'X_train': X_train, 'X_valid': X_valid,'y_train': y_train, 'y_valid': y_valid}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_loc = '../glove.6B.100d.txt'\n",
    "glove = np.loadtxt(glove_loc,dtype='str',comments=None)\n",
    "\n",
    "vectors = glove[:,1:].astype('float')\n",
    "words = glove[:,0]\n",
    "\n",
    "del glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "\n",
    "for sentences in features:\n",
    "    sentences = clean_string(sentences)\n",
    "    sentences = nltk.word_tokenize(sentences)\n",
    "    for word in sentences:\n",
    "        vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 words not found.\n"
     ]
    }
   ],
   "source": [
    "word_lookup = {word:vector for word,vector in zip(words,vectors)}\n",
    "\n",
    "word_index = dict()\n",
    "ind = 2\n",
    "not_found = 0\n",
    "\n",
    "embeds = dict()\n",
    "\n",
    "for i,word in enumerate(vocab.keys()):\n",
    "    vector = word_lookup.get(word,None)\n",
    "\n",
    "    if vector is not None:\n",
    "        word_index[word] = ind\n",
    "        embeds[ind] = np.copy(vector)\n",
    "        ind+=1\n",
    "    else:\n",
    "        not_found +=1\n",
    "        word_index[word] = UNK_ID\n",
    "\n",
    "print(f'{not_found} words not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(utt1):\n",
    "    utt2 = [word_index.get(word,UNK_ID) for word in nltk.word_tokenize(clean_string(utt1))]\n",
    "    utt3 = utt2[:MAX_LEN]\n",
    "    utt4 = utt3 + [PAD_ID]*(MAX_LEN - len(utt3))\n",
    "    utt5 = np.mean([embeds[i] for i in utt4 if i>1],axis=0)\n",
    "    if type(utt5) == np.float64:\n",
    "        utt5 = np.random.rand(100)\n",
    "    if type(utt5) == np.float64:\n",
    "        print('here')\n",
    "    return utt5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "training_dict['X_train'] = [word_to_index(word) for word in training_dict['X_train']]\n",
    "training_dict['X_valid'] = [word_to_index(word) for word in training_dict['X_valid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(features,labels):\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        svm.SVC(C=10.0, gamma=\"scale\", kernel=\"rbf\")\n",
    "    )\n",
    "    return clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_test(clf,features,labels):\n",
    "    pred = clf.predict(features)\n",
    "    true = labels\n",
    "\n",
    "    result_string = classification_report(true, pred, digits=3)\n",
    "    print(confusion_matrix(true, pred))\n",
    "    print(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84  24]\n",
      " [ 13 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.866     0.778     0.820       108\n",
      "         1.0      0.817     0.892     0.853       120\n",
      "\n",
      "    accuracy                          0.838       228\n",
      "   macro avg      0.841     0.835     0.836       228\n",
      "weighted avg      0.840     0.838     0.837       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 30]\n",
      " [21 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.814     0.754     0.783       122\n",
      "         1.0      0.739     0.802     0.769       106\n",
      "\n",
      "    accuracy                          0.776       228\n",
      "   macro avg      0.777     0.778     0.776       228\n",
      "weighted avg      0.779     0.776     0.777       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 31]\n",
      " [12 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.888     0.754     0.815       126\n",
      "         1.0      0.744     0.882     0.807       102\n",
      "\n",
      "    accuracy                          0.811       228\n",
      "   macro avg      0.816     0.818     0.811       228\n",
      "weighted avg      0.823     0.811     0.812       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  23]\n",
      " [ 31 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.702     0.760     0.730        96\n",
      "         1.0      0.815     0.765     0.789       132\n",
      "\n",
      "    accuracy                          0.763       228\n",
      "   macro avg      0.758     0.763     0.760       228\n",
      "weighted avg      0.767     0.763     0.764       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99 19]\n",
      " [23 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.811     0.839     0.825       118\n",
      "         1.0      0.821     0.791     0.806       110\n",
      "\n",
      "    accuracy                          0.816       228\n",
      "   macro avg      0.816     0.815     0.815       228\n",
      "weighted avg      0.816     0.816     0.816       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94  20]\n",
      " [ 11 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.825     0.858       114\n",
      "         1.0      0.837     0.904     0.869       114\n",
      "\n",
      "    accuracy                          0.864       228\n",
      "   macro avg      0.866     0.864     0.864       228\n",
      "weighted avg      0.866     0.864     0.864       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 27]\n",
      " [19 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.833     0.779     0.805       122\n",
      "         1.0      0.763     0.821     0.791       106\n",
      "\n",
      "    accuracy                          0.798       228\n",
      "   macro avg      0.798     0.800     0.798       228\n",
      "weighted avg      0.801     0.798     0.798       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95  17]\n",
      " [ 15 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.864     0.848     0.856       112\n",
      "         1.0      0.856     0.871     0.863       116\n",
      "\n",
      "    accuracy                          0.860       228\n",
      "   macro avg      0.860     0.859     0.860       228\n",
      "weighted avg      0.860     0.860     0.860       228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87   6]\n",
      " [ 29 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.750     0.935     0.833        93\n",
      "         1.0      0.946     0.784     0.857       134\n",
      "\n",
      "    accuracy                          0.846       227\n",
      "   macro avg      0.848     0.860     0.845       227\n",
      "weighted avg      0.866     0.846     0.847       227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vaibhav/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99 15]\n",
      " [26 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.792     0.868     0.828       114\n",
      "         1.0      0.853     0.770     0.809       113\n",
      "\n",
      "    accuracy                          0.819       227\n",
      "   macro avg      0.822     0.819     0.819       227\n",
      "weighted avg      0.822     0.819     0.819       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(features):\n",
    "    train_x = [features[index] for index in train_index]\n",
    "    train_x = [word_to_index(word) for word in train_x]\n",
    "    train_y = [labels[index] for index in train_index]\n",
    "    test_x = [features[index] for index in test_index]\n",
    "    test_x = [word_to_index(word) for word in test_x]\n",
    "    test_y = [labels[index] for index in test_index]\n",
    "    clf = svm_train(train_x,train_y)\n",
    "    svm_test(clf,test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190  53]\n",
      " [ 62 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.754     0.782     0.768       243\n",
      "         1.0      0.786     0.759     0.772       257\n",
      "\n",
      "    accuracy                          0.770       500\n",
      "   macro avg      0.770     0.770     0.770       500\n",
      "weighted avg      0.771     0.770     0.770       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm_train(training_dict['X_train'],training_dict['y_train'])\n",
    "\n",
    "svm_test(clf,training_dict['X_valid'],training_dict['y_valid'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8296d0786e9b384ebb7f91942e232033740bae4a9ae1f1bba7a3651c8060b4f0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
